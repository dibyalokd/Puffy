

import sqlite3
import re

def ingest_to_sqlite(file_path, db_name="blueprints.db"):
    # 1. Connect and Setup Table
    conn = sqlite3.connect(db_name)
    cursor = conn.cursor()
    
    # Create table: blueprint_id is the Primary Key to ensure uniqueness
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS blueprints (
            blueprint_id TEXT PRIMARY KEY,
            data TEXT
        )
    ''')

    # 2. Parse the File
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    blocks = content.split('<-------->')
    
    data_to_insert = []

    for block in blocks:
        block = block.strip()
        if not block:
            continue
            
        # Regex to find the ID inside the brackets
        match = re.search(r'# Blueprint:\s*\[(.*?)\]', block)
        
        if match:
            blueprint_id = match.group(1).strip()
            # Strip the first line (the header) to get the body
            data_body = re.sub(r'# Blueprint:.*?\n', '', block, count=1).strip()
            
            data_to_insert.append((blueprint_id, data_body))

    # 3. Batch Insert (Atomic Transaction)
    # REPLACE handles the "unique ID" requirement‚Äîif ID exists, it updates the data.
    cursor.executemany('''
        INSERT OR REPLACE INTO blueprints (blueprint_id, data)
        VALUES (?, ?)
    ''', data_to_insert)

    conn.commit()
    conn.close()
    print(f"‚úÖ Processed {len(data_to_insert)} blueprints into {db_name}")

if __name__ == "__main__":
    ingest_to_sqlite("data.txt")




import chromadb
import re

def ingest_blueprints(file_path):
    # 1. Initialize Local Persistent Client
    client = chromadb.PersistentClient(path="./chroma_db")
    
    # Use a specific embedding function if you want, 
    # otherwise it uses the default (all-MiniLM-L6-v2)
    collection = client.get_or_create_collection(name="blueprints_collection")

    with open(file_path, 'r') as f:
        content = f.read()

    # 2. Split into blocks
    blocks = content.split('<-------->')
    
    ids_to_insert = []
    docs_to_insert = []

    for block in blocks:
        block = block.strip()
        if not block:
            continue
            
        # Extract ID: looks for # Blueprint: [ID_HERE]
        match = re.search(r'# Blueprint:\s*\[(.*?)\]', block)
        
        if match:
            blueprint_id = match.group(1).strip()
            # Body: everything after the first newline
            lines = block.split('\n')
            data_body = "\n".join(lines[1:]).strip()

            ids_to_insert.append(blueprint_id)
            docs_to_insert.append(data_body)

    # 3. Batch Upload (This prevents the timeout)
    if ids_to_insert:
        print(f"üì¶ Found {len(ids_to_insert)} blueprints. Starting batch ingestion...")
        try:
            # upsert is better: it updates if the ID already exists
            collection.upsert(
                documents=docs_to_insert,
                ids=ids_to_insert
            )
            print("‚ú® Successfully indexed all data.")
        except Exception as e:
            print(f"‚ùå Error during ingestion: {e}")

if __name__ == "__main__":
    ingest_blueprints("data.txt")




---------

import chromadb
import re

def ingest_blueprints(file_path):
    # 1. Initialize Chroma Client (Persistent)
    client = chromadb.PersistentClient(path="./chroma_db")
    
    # Create or get the collection
    collection = client.get_or_create_collection(name="blueprints_collection")

    with open(file_path, 'r') as f:
        content = f.read()

    # 2. Split by the separator
    blocks = content.split('<-------->')

    for block in blocks:
        block = block.strip()
        if not block:
            continue
            
        # 3. Extract ID using Regex
        # Matches "# Blueprint: [ids]" and captures the "ids" part
        match = re.search(r'# Blueprint:\s*\[(.*?)\]', block)
        
        if match:
            blueprint_id = match.group(1).strip()
            # Remove the header line to get just the "some data" body
            data_body = re.sub(r'# Blueprint:.*?\n', '', block, count=1).strip()

            # 4. Upsert into Chroma
            # We use upsert so it updates if the ID already exists
            collection.upsert(
                documents=[data_body],
                ids=[blueprint_id],
                metadatas=[{"source": "text_file"}]
            )
            print(f"‚úÖ Indexed Blueprint: {blueprint_id}")

if __name__ == "__main__":
    ingest_blueprints("data.txt")
